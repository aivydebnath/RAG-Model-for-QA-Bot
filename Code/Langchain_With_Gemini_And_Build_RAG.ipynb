{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "2dwxk3FD4gJe",
        "-TbsjM7hK6PR",
        "6fVI3d0BPaPQ"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aivydebnath/RAG-Model-for-QA-Bot/blob/main/Code/Langchain_With_Gemini_And_Build_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installations"
      ],
      "metadata": {
        "id": "2dwxk3FD4gJe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "wgALz5M7I9dQ"
      },
      "outputs": [],
      "source": [
        "! pip install -q --upgrade google-generativeai langchain-google-genai pypdf langchain langchain-community pinecone-client PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "import warnings\n",
        "from pathlib import Path as p\n",
        "from pprint import pprint\n",
        "import pandas as pd\n",
        "from langchain import PromptTemplate\n",
        "import os\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "import textwrap\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from pinecone import Pinecone\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Pinecone as PineconeVectorStore\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "# restart python kernal if issues with langchain import."
      ],
      "metadata": {
        "id": "0Iptw8905Ztl"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# API"
      ],
      "metadata": {
        "id": "bLwVoDWDKtCy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I do not have OPENAI API(Credits expired), hence used Google API Key to make this project."
      ],
      "metadata": {
        "id": "8aRNp6FUUWM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['PINECONE_API_KEY']=userdata.get('PINECONE_API')\n",
        "os.environ['GOOGLE_API_KEY']=userdata.get('GOOGLE_API_KEY')\n",
        "GOOGLE_API_KEY=os.environ['GOOGLE_API_KEY']"
      ],
      "metadata": {
        "id": "IyFw97EIKupx"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Markdown"
      ],
      "metadata": {
        "id": "3bhXiNBlVhfC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_markdown(text):\n",
        "  text = text.replace('â€¢', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
        ""
      ],
      "metadata": {
        "id": "tcP1T4O8VfiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use LangChain to Access Gemini API"
      ],
      "metadata": {
        "id": "-TbsjM7hK6PR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\",google_api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "vknP_oOWK-k7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = llm.invoke(\"What are the usecases of LLMs?\")\n"
      ],
      "metadata": {
        "id": "hvY2YkFoLDO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "id": "LyU3BmKWU07z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(result.content)"
      ],
      "metadata": {
        "id": "ar8KNtZILE47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm2 = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\",google_api_key=GOOGLE_API_KEY)\n",
        "result2 = llm.invoke(\"What are the usecases of LLMs?\")\n",
        "to_markdown(result2.content)"
      ],
      "metadata": {
        "id": "b0rZYyKHVtjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RAG"
      ],
      "metadata": {
        "id": "XeXPMf5y5D_R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ITC"
      ],
      "metadata": {
        "id": "Motl2kFsWQhd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extract text from the PDF"
      ],
      "metadata": {
        "id": "6fVI3d0BPaPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_doc(directory):\n",
        "    file_loader=PyPDFLoader(\"/content/sample_data/ITC-Report-and-Accounts-2023.pdf\")\n",
        "    documents=file_loader.load()\n",
        "    return documents"
      ],
      "metadata": {
        "id": "S-49AhCcxvvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc=read_doc('')\n",
        "len(doc)"
      ],
      "metadata": {
        "id": "UYaeptmjx3rO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc[10]"
      ],
      "metadata": {
        "id": "qzWXrF63A93t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RAG Pipeline: Embedding + Gemini (LLM)"
      ],
      "metadata": {
        "id": "QQ7OlzvWSRE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\",google_api_key=GOOGLE_API_KEY)\n",
        "\n",
        "index_name=\"langchainvector\"\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=1000)\n",
        "texts = text_splitter.split_documents(doc)"
      ],
      "metadata": {
        "id": "oenB_PKkSpr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts[0]"
      ],
      "metadata": {
        "id": "-NLJRNMDDzDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pinecone_vector_store = PineconeVectorStore.from_documents(texts, embeddings, index_name=index_name)"
      ],
      "metadata": {
        "id": "IA3aTueIDTXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Which quater cigerettes has performed well?\"\n",
        "similar_docs=pinecone_vector_store.similarity_search(question)"
      ],
      "metadata": {
        "id": "kCo6qMNHGgGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\",google_api_key=GOOGLE_API_KEY,\n",
        "                             temperature=0.4,convert_system_message_to_human=True)"
      ],
      "metadata": {
        "id": "_B014BkyG_Qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    model,\n",
        "    retriever=pinecone_vector_store.as_retriever(),\n",
        "    return_source_documents=True,\n",
        "    chain_type=\"stuff\"\n",
        ")\n",
        "\n",
        "qa_chain.invoke(question)"
      ],
      "metadata": {
        "id": "a3CrM0l3Hc__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Can you tell the names of the products ITC has?\"\n",
        "result = qa_chain({\"query\": question})\n",
        "result[\"result\"]"
      ],
      "metadata": {
        "id": "C683CMhDHtA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(result[\"result\"])"
      ],
      "metadata": {
        "id": "gR9NB2OLIp7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer.\n",
        "{context}\n",
        "Question: {question}\n",
        "Helpful Answer:\"\"\"\n",
        "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)# Run chain\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    model,\n",
        "    retriever=pinecone_vector_store.as_retriever(),\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
        ")\n"
      ],
      "metadata": {
        "id": "TGFjxwzcUb02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Can you tell the names of the products ITC has?\"\n",
        "result = qa_chain({\"query\": question})\n",
        "result[\"result\"]"
      ],
      "metadata": {
        "id": "og-CJ7iaMYJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(result[\"result\"])"
      ],
      "metadata": {
        "id": "BwZpAwFWMbor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Describe Random forest?\"\n",
        "result = qa_chain({\"query\": question})\n",
        "Markdown(result[\"result\"])"
      ],
      "metadata": {
        "id": "CFNBXo0kJKkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HUL\n"
      ],
      "metadata": {
        "id": "yC2eqZrTWReh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extraction text from PDF"
      ],
      "metadata": {
        "id": "oR6IdVQJYSFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_doc(directory):\n",
        "    file_loader=PyPDFLoader(\"/content/sample_data/Annual_Report___2022_23__2__bWICfx.pdf\")\n",
        "    documents=file_loader.load()\n",
        "    return documents"
      ],
      "metadata": {
        "id": "73U59N5IWS8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc=read_doc('')\n",
        "len(doc)"
      ],
      "metadata": {
        "id": "cv-E-dMyWWyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc[0]"
      ],
      "metadata": {
        "id": "E_ZCppOUWZ6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RAG Pipeline: Embedding + Gemini(LLM)"
      ],
      "metadata": {
        "id": "wRDupov-YX-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\",google_api_key=GOOGLE_API_KEY)\n",
        "\n",
        "index_name=\"langchainvector\"\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=1000)\n",
        "texts = text_splitter.split_documents(doc)"
      ],
      "metadata": {
        "id": "xUbXV6lEW_hV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts[0]"
      ],
      "metadata": {
        "id": "5DK-aAQUXFIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pinecone_vector_store = PineconeVectorStore.from_documents(texts, embeddings, index_name=index_name)"
      ],
      "metadata": {
        "id": "PPdSltFwXOyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\",google_api_key=GOOGLE_API_KEY,\n",
        "                             temperature=0.4,convert_system_message_to_human=True)"
      ],
      "metadata": {
        "id": "zs8HoCwcXQQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"How HUL performed?\"\n",
        "similar_docs=pinecone_vector_store.similarity_search(question)"
      ],
      "metadata": {
        "id": "jW0Xx3FzXW9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    model,\n",
        "    retriever=pinecone_vector_store.as_retriever(),\n",
        "    return_source_documents=True,\n",
        "    chain_type=\"stuff\"\n",
        ")\n",
        "\n",
        "qa_chain.invoke(question)"
      ],
      "metadata": {
        "id": "shXMW8j3Xbkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"How HUL performed?Is it better than last year?What are the products of HUL?\"\n",
        "result = qa_chain({\"query\": question})\n",
        "result[\"result\"]"
      ],
      "metadata": {
        "id": "OBzbnAH7XlRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(result[\"result\"])"
      ],
      "metadata": {
        "id": "-EWf1ljyXiUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Keep the answer as concise as possible. Always say thanks for asking! Happy to help at the end of the answer.\n",
        "{context}\n",
        "Question: {question}\n",
        "Helpful Answer:\"\"\"\n",
        "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    model,\n",
        "    retriever=pinecone_vector_store.as_retriever(),\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
        ")\n"
      ],
      "metadata": {
        "id": "jOoqlM3FYnCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is ML?\"\n",
        "result = qa_chain({\"query\": question})\n",
        "result[\"result\"]"
      ],
      "metadata": {
        "id": "VWUUYrRoY0gg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(result[\"result\"])"
      ],
      "metadata": {
        "id": "2x--bC9aY1q6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"How HUL performed?Is it better than last year?What are the products of HUL?\"\n",
        "result = qa_chain({\"query\": question})\n",
        "result[\"result\"]"
      ],
      "metadata": {
        "id": "0WNmyLX1YsBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(result[\"result\"])"
      ],
      "metadata": {
        "id": "9ln8a4cpYtN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What are the products of HUL in Beauty and Personal Care?\"\n",
        "result = qa_chain({\"query\": question})\n",
        "result[\"result\"]"
      ],
      "metadata": {
        "id": "gDy6X75LY1l5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(result[\"result\"])"
      ],
      "metadata": {
        "id": "jdBswPfOY6n0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By creating this QA Chat bot, we can"
      ],
      "metadata": {
        "id": "MA5uYzunrnSb"
      }
    }
  ]
}